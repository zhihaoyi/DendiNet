{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b402ffd8-b978-4c61-91ea-bde0a99ebee2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# return to main dir\n",
    "current_directory = os.getcwd()\n",
    "main_dir = os.path.dirname(current_directory)\n",
    "sys.path.append(main_dir)\n",
    "\n",
    "from utils.dataset_pipeline import dataset_pipeline\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from configs.transformer_loader import Configs\n",
    "from configs.transformer_val_loader import Configs as Configs_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1dbbfa3c-0159-42cd-b05e-e8f41dc516b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random seed\n",
    "seed = 77\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "080fc067-f8d7-448e-9c71-ac030874c22d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Training drive:\n",
    "Cycle_1,2,3,4, NN, UDDS, LA92\n",
    "\n",
    "Testing drive:\n",
    "US06, HWFTa, HWFTb, eneroc\n",
    "'''\n",
    "batch_size = 1024\n",
    "val_ratio = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a26d3639-b21a-4f63-a441-599ff37a6455",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-20deg: Cycle_1 is loaded, containing 50712 samples.\n",
      "-20deg: Cycle_2 is loaded, containing 50375 samples.\n",
      "-20deg: Cycle_3 is loaded, containing 50147 samples.\n",
      "-20deg: Cycle_4 is loaded, containing 50345 samples.\n",
      "-20deg: C_NN is loaded, containing 45363 samples.\n",
      "-20deg: C_UDDS is loaded, containing 89405 samples.\n",
      "-20deg: C_LA92_P is loaded, containing 57146 samples.\n",
      "---------- all -20deg datasets are uploaded ----------\n",
      "-10deg: Cycle_1 is loaded, containing 60234 samples.\n",
      "-10deg: Cycle_2 is loaded, containing 59712 samples.\n",
      "-10deg: Cycle_3 is loaded, containing 56857 samples.\n",
      "-10deg: Cycle_4 is loaded, containing 61102 samples.\n",
      "-10deg: C_NN is loaded, containing 52522 samples.\n",
      "-10deg: C_UDDS is loaded, containing 109717 samples.\n",
      "-10deg: C_LA92_P is loaded, containing 69568 samples.\n",
      "---------- all -10deg datasets are uploaded ----------\n",
      "0deg: Cycle_1 is loaded, containing 88007 samples.\n",
      "0deg: Cycle_2 is loaded, containing 83732 samples.\n",
      "0deg: Cycle_3 is loaded, containing 62466 samples.\n",
      "0deg: Cycle_4 is loaded, containing 77052 samples.\n",
      "0deg: C_NN is loaded, containing 63279 samples.\n",
      "0deg: C_UDDS is loaded, containing 128522 samples.\n",
      "0deg: C_LA92_P is loaded, containing 82666 samples.\n",
      "---------- all 0deg datasets are uploaded ----------\n",
      "10deg: Cycle_1 is loaded, containing 93794 samples.\n",
      "10deg: Cycle_2 is loaded, containing 81096 samples.\n",
      "10deg: Cycle_3 is loaded, containing 100796 samples.\n",
      "10deg: Cycle_4 is loaded, containing 98987 samples.\n",
      "10deg: C_NN is loaded, containing 105109 samples.\n",
      "10deg: C_UDDS is loaded, containing 210465 samples.\n",
      "10deg: C_LA92_P is loaded, containing 125951 samples.\n",
      "---------- all 10deg datasets are uploaded ----------\n",
      "25deg: Cycle_1 is loaded, containing 109641 samples.\n",
      "25deg: Cycle_2 is loaded, containing 111268 samples.\n",
      "25deg: Cycle_3 is loaded, containing 102441 samples.\n",
      "25deg: Cycle_4 is loaded, containing 120863 samples.\n",
      "25deg: C_NN is loaded, containing 116982 samples.\n",
      "25deg: C_UDDS is loaded, containing 224187 samples.\n",
      "25deg: C_LA92_P is loaded, containing 140874 samples.\n",
      "---------- all 25deg datasets are uploaded ----------\n",
      "25deg: US06 is loaded, containing 48061 samples.\n",
      "---------- all 25deg datasets are uploaded ----------\n",
      "25deg: HWFTa is loaded, containing 75955 samples.\n",
      "---------- all 25deg datasets are uploaded ----------\n",
      "25deg: HWFTb is loaded, containing 75811 samples.\n",
      "---------- all 25deg datasets are uploaded ----------\n",
      "25deg: eneroc is loaded, containing 29633 samples.\n",
      "---------- all 25deg datasets are uploaded ----------\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "temp: ['-20deg/', '-10deg/', '0deg/', '10deg/', '25deg/']\n",
    "drive cycle: ['Cycle_1', 'Cycle_2', 'Cycle_3', 'Cycle_4', 'NN', 'UDDS', 'LA92']\n",
    "'''\n",
    "# LSTM and GRU dataloader configs\n",
    "configs = Configs()\n",
    "configs_val = Configs_val()\n",
    "\n",
    "# training&validation pipeline\n",
    "train_val_dataset = dataset_pipeline(main_dir+'/data/', ['-20deg/', '-10deg/', '0deg/', '10deg/', '25deg/'],\n",
    "                                    ['Cycle_1', 'Cycle_2', 'Cycle_3', 'Cycle_4', 'C_NN', 'C_UDDS', 'C_LA92_P'], configs)\n",
    "\n",
    "# testing pipeline\n",
    "US06_test_dataset = dataset_pipeline(main_dir+'/data/', ['25deg/'], ['US06'], configs_val)\n",
    "HWFTa_test_dataset = dataset_pipeline(main_dir+'/data/', ['25deg/'], ['HWFTa'], configs_val)\n",
    "HWFTb_test_dataset = dataset_pipeline(main_dir+'/data/', ['25deg/'], ['HWFTb'], configs_val)\n",
    "eneroc_test_dataset = dataset_pipeline(main_dir+'/data/', ['25deg/'], ['eneroc'], configs_val, convert2soc=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d70116ab-7a8a-480a-bd81-7bd39b0cc346",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into training and validation dataset\n",
    "val_size = int(val_ratio * len(train_val_dataset))\n",
    "train_dataset, val_dataset = random_split(train_val_dataset, [len(train_val_dataset) - val_size, val_size])\n",
    "\n",
    "# training and validation dataloader\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# testing dataloader\n",
    "US06_test_loader = DataLoader(US06_test_dataset, batch_size=batch_size)\n",
    "HWFTa_test_loader = DataLoader(HWFTa_test_dataset, batch_size=batch_size)\n",
    "HWFTb_test_loader = DataLoader(HWFTb_test_dataset, batch_size=batch_size)\n",
    "eneroc_test_loader = DataLoader(eneroc_test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25877343-d9cd-4d15-87e2-7deea0bd4748",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all dataloaders are saved!\n"
     ]
    }
   ],
   "source": [
    "# save the dataloader to pkl\n",
    "# train\n",
    "with open(main_dir+'/dataloader/save/transformer/train_loader.pkl', 'wb') as file:\n",
    "    pickle.dump(train_loader, file)\n",
    "with open(main_dir+'/dataloader/save/transformer/val_loader.pkl', 'wb') as file:\n",
    "    pickle.dump(val_loader, file)\n",
    "\n",
    "# # test\n",
    "with open(main_dir+'/dataloader/save/transformer/US06_test_loader.pkl', 'wb') as file:\n",
    "    pickle.dump(US06_test_loader, file)\n",
    "with open(main_dir+'/dataloader/save/transformer/HWFTa_test_loader.pkl', 'wb') as file:\n",
    "    pickle.dump(HWFTa_test_loader, file)\n",
    "with open(main_dir+'/dataloader/save/transformer/HWFTb_test_loader.pkl', 'wb') as file:\n",
    "    pickle.dump(HWFTb_test_loader, file)\n",
    "with open(main_dir+'/dataloader/save/transformer/eneroc_test_loader.pkl', 'wb') as file:\n",
    "    pickle.dump(eneroc_test_loader, file)\n",
    "    \n",
    "print(f'all dataloaders are saved!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e84eaa-626c-4513-ab99-00d76a2a663d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
